import os
from PIL import Image
from torch.utils.data import Dataset
import torch
import torch.nn.functional as F

class TripletDataset(Dataset):
    """
    TripletDataset is a custom PyTorch Dataset designed for loading and managing triplet data 
    essential for training models using triplet loss.

    Each sample in the dataset consists of three images:
        - **Anchor**: The reference image.
        - **Positive**: An image similar to the anchor.
        - **Negative**: An image dissimilar to the anchor.

    This structure facilitates effective training for tasks such as metric learning and face 
    recognition by ensuring that the model learns to distinguish between similar and dissimilar pairs.

    Attributes:
        image_dir (str):
            Path to the directory containing all images.
        train_triplets (List[Tuple[str, str, str]]):
            List of triplet tuples, where each tuple contains the filenames of the anchor, positive, 
            and negative images respectively.
        transform (callable, optional):
            A function or torchvision.transforms to apply to the images for preprocessing, such as 
            resizing, normalization, or augmentation.

    Methods:
        __init__(self, image_dir, train_triplets, transform=None):
            Initializes the TripletDataset with the specified image directory, triplet list, and optional 
            transformations.
        __len__(self):
            Returns the total number of triplet samples in the dataset.
        __getitem__(self, idx):
            Retrieves the anchor, positive, and negative images for the specified index after applying 
            transformations.

    Example:
        ```python

        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

        train_triplets = [
            ('anchor1.jpg', 'positive1.jpg', 'negative1.jpg'),
            ('anchor2.jpg', 'positive2.jpg', 'negative2.jpg'),
            # Add more triplets as needed
        ]

        dataset = TripletDataset(
            image_dir='/path/to/images',
            train_triplets=train_triplets,
            transform=transform
        )

        anchor, positive, negative = dataset[0]
        # anchor, positive, negative are transformed image tensors
        ```

    Notes:
        - Ensure that all image filenames specified in `train_triplets` exist within the `image_dir`.
        - The `transform` should be compatible with PIL Images and return tensors suitable for model input.
        - This dataset returns `None` for triplets with missing images. Handle such cases appropriately 
        in your data loader to avoid issues during training.
    """
    def __init__(self, image_dir, train_triplets, transform=None):
        """
        Initializes the TripletDataset.

        The TripletDataset is designed for loading and managing triplet data, which is 
        essential for training models using triplet loss. Each triplet consists of an 
        anchor image, a positive image (similar to the anchor), and a negative image (dissimilar 
        to the anchor). This dataset facilitates efficient loading, transformation, and retrieval 
        of such triplets for model training and evaluation.

        Args:
            image_dir (str): 
            Path to the directory containing all images.
            train_triplets (List[Tuple[str, str, str]]): 
            List of triplets, where each triplet is a tuple containing paths to the anchor, positive, 
                and negative images respectively.
            transform (callable, optional): 
            A function or torchvision.transforms to apply to the images for preprocessing. This can 
                include operations like resizing, normalization, augmentation, etc.

        Attributes:
            image_dir (str): Stores the path to the image directory.
            train_triplets (List[Tuple[str, str, str]]): Stores the list of image triplets.
            attributes (Dict[str, Any]): Stores the mapping of image filenames to their attributes.
            transform (callable, optional): Stores the transformation function to be applied to the images.

        Example:
            >>> from torchvision import transforms
            >>> transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
            ])
            >>> train_triplets = [
                ('anchor1.jpg', 'positive1.jpg', 'negative1.jpg'),
                ('anchor2.jpg', 'positive2.jpg', 'negative2.jpg')
            ]
            >>> dataset = TripletDataset(
                image_dir='/path/to/images',
                train_triplets=train_triplets,
                transform=transform
            )

        Notes:
            - Ensure that all image paths provided in `train_triplets` exist within the `image_dir`.
            - The `transform` function should be compatible with PIL Images and return tensors suitable for model input.
            - This dataset returns `None` for triplets with missing images. Implement appropriate handling in your data loader to filter out such cases.
        """
        self.image_dir = image_dir
        self.train_triplets = train_triplets
        self.transform = transform

    def __len__(self):
        """
        Returns the total number of triplet samples in the training dataset.

        This method allows instances of the dataset to be used with built-in functions like len(),
        providing the number of triplet samples available for training. Each triplet consists of
        an anchor, a positive example, and a negative example, which are used to train models
        for tasks such as metric learning and face recognition.

        Attributes:
            train_triplets (List[Tuple[Any, Any, Any]]): A list containing all the triplet samples.
                Each triplet is a tuple of (anchor, positive, negative).

        Returns:
            int: The number of triplet samples in the training dataset.

        Example:
            >>> dataset = TripletMethod(train_triplets=[(a1, p1, n1), (a2, p2, n2)])
            >>> len(dataset)
            2
        """
        return len(self.train_triplets)

    def __getitem__(self, idx):
        """
        Retrieves the triplet of images (anchor, positive, negative) at the specified index.
        This method allows instances of the dataset to be used with built-in functions like `len()`,
        providing the necessary images for training models using triplet-based approaches such as
        metric learning or face recognition.
        The method performs the following steps:
            1. **Retrieve Paths**: Accesses the file paths for the anchor, positive, and negative images
               from the `train_triplets` list using the provided index.
            2. **Check Existence**: Verifies that all three image files exist within the specified
               `image_dir`. If any file is missing, a warning is printed, and the method returns `None`
               to skip this triplet.
            3. **Load Images**: Opens each image file and converts them to RGB format using `Image.open`.
            4. **Apply Transformations**: If a transformation function is provided (`self.transform`),
               it is applied to each of the three images.
            5. **Return Triplet**: Returns a tuple containing the processed anchor, positive, and negative
               images.
        Args:
            idx (int): The index of the triplet to retrieve from the `train_triplets` list.
        Returns:
            tuple or None:
                - **tuple**: A tuple containing the transformed anchor, positive, and negative images.
                - **None**: Returned if one or more image files in the triplet are not found.
        Example:
            ```python
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
            ])
            train_triplets = [
                ('anchor1.jpg', 'positive1.jpg', 'negative1.jpg'),
                ('anchor2.jpg', 'positive2.jpg', 'negative2.jpg'),
                # Add more triplets as needed
            ]
            dataset = TripletMethod(train_triplets=train_triplets, image_dir='/path/to/images', transform=transform)
            anchor, positive, negative = dataset[0]
            # Expected output: (anchor_image_tensor, positive_image_tensor, negative_image_tensor)
            ```
        """
        anchor_path, positive_path, negative_path = self.train_triplets[idx]
        try:
            anchor = Image.open(os.path.join(self.image_dir, anchor_path)).convert("RGB")
            positive = Image.open(os.path.join(self.image_dir, positive_path)).convert("RGB")
            negative = Image.open(os.path.join(self.image_dir, negative_path)).convert("RGB")
        except FileNotFoundError:
            # print(f"Skipping triplet {idx} due to missing image")
            return None

        if self.transform:
            anchor = self.transform(anchor)
            positive = self.transform(positive)
            negative = self.transform(negative)

        return anchor, positive, negative


class QueryDataset(Dataset):
    """
    QueryDataset is a custom PyTorch Dataset designed for loading and managing query images, 
    typically used in retrieval or evaluation tasks. Each sample in the dataset consists of 
    a single image and its corresponding filename.

    Attributes:
        image_dir (str):
            Path to the directory containing all query images.
        query_triplets (List[Tuple[str]]):
            List of tuples, where each tuple contains the filename of a query image.
        transform (callable, optional):
            A function or torchvision.transforms to apply to the images for preprocessing, such as 
            resizing, normalization, or augmentation.

    Methods:
        __init__(self, image_dir, query_triplets, transform=None):
            Initializes the QueryDataset with the specified image directory, query list, and optional 
            transformations.
        __len__(self):
            Returns the total number of query samples in the dataset.
        __getitem__(self, idx):
            Retrieves the query image and its filename for the specified index after applying 
            transformations.

    Example:
        ```python

        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])
        query_triplets = [
            ('query1.jpg',),
            ('query2.jpg',),
            # Add more query images as needed
        ]
        dataset = QueryDataset(
            image_dir='/path/to/query_images',
            query_triplets=query_triplets,
            transform=transform
        )
        query_image, query_path = dataset[0]
        # query_image is a transformed image tensor
        # query_path is 'query1.jpg'
        ```

    Notes:
        - Ensure that all image filenames provided in `query_triplets` exist within the `image_dir`.
        - The `transform` function should be compatible with PIL Images and return tensors suitable for model input.
        - This dataset returns processed query images along with their filenames, which can be useful for tracking and evaluation purposes.
    """
    def __init__(self, image_dir, query_triplets, transform=None):
        """
        Dataset for query images.

        The `QueryDataset` is designed for loading and managing query images, which are typically 
        used in retrieval or evaluation tasks. Each query consists of a single image, and this dataset 
        facilitates efficient loading, transformation, and retrieval of such images for model 
        inference and evaluation.

        Args:
            image_dir (str): 
                Path to the directory containing all query images.
            query_triplets (List[Tuple[str]]): 
                List of query tuples, where each tuple contains the filename of a query image.
            transform (callable, optional): 
                A function or torchvision.transforms to apply to the images for preprocessing. This can 
                include operations like resizing, normalization, augmentation, etc.

        Attributes:
            image_dir (str): 
                Stores the path to the image directory containing query images.
            query_triplets (List[Tuple[str]]): 
                Stores the list of query image filenames.
            transform (callable, optional): 
                Stores the transformation function to be applied to the images.

        Example:
            ```python

            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
            ])
            query_triplets = [
                ('query1.jpg',),
                ('query2.jpg',),
                # Add more query images as needed
            ]
            dataset = QueryDataset(
                image_dir='/path/to/query_images',
                query_triplets=query_triplets,
                transform=transform
            )
            query_image, query_path = dataset[0]
            # Expected output: (query_image_tensor, 'query1.jpg')
            ```

        Notes:
            - Ensure that all image filenames provided in `query_triplets` exist within the `image_dir`.
            - The `transform` function should be compatible with PIL Images and return tensors suitable for model input.
            - This dataset returns processed query images along with their filenames, which can be useful for tracking and evaluation purposes.
        """
        self.image_dir = image_dir
        self.query_triplets = query_triplets
        self.transform = transform

    def __len__(self):
        return len(self.query_triplets)

    def __getitem__(self, idx):
        query_image_path = self.query_triplets[idx][0]
        query_image = Image.open(os.path.join(self.image_dir, query_image_path)).convert("RGB")
        if self.transform:
            query_image = self.transform(query_image)
        return query_image, query_image_path

def collate_fn(batch):
    """
    Collate function for handling None values in a batch.

    This function is used as the collate_fn argument in PyTorch DataLoader to handle cases
    where the __getitem__ method of a dataset returns None for certain samples. It filters
    out the None values from the batch before passing it to the default collate function.

    Args:
        batch (List): A list of samples returned by the dataset's __getitem__ method.

    Returns:
        Any: The processed batch after filtering out None values.

    Example:
        >>> dataset = MyDataset(...)
        >>> dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn)
    """
    batch = [x for x in batch if x is not None]
    if len(batch) == 0:
        return None
    return torch.utils.data.dataloader.default_collate(batch)

def triplet_loss(anchor, positive, negative, margin=1.0):
    """
    Calculates the triplet loss function.

    The triplet loss encourages the distance between an anchor and a positive example 
    (similar to the anchor) to be smaller than the distance between the anchor and a 
    negative example (dissimilar to the anchor) by at least a specified margin.

    Args:
        anchor (torch.Tensor): 
            Embeddings of the anchor samples. Shape: (batch_size, embedding_dim).
        positive (torch.Tensor): 
            Embeddings of the positive samples. Shape: (batch_size, embedding_dim).
        negative (torch.Tensor): 
            Embeddings of the negative samples. Shape: (batch_size, embedding_dim).
        margin (float, optional): 
            The minimum required difference between positive and negative pairs. Default is 1.0.

    Returns:
        torch.Tensor:
            The computed triplet loss as a scalar tensor.

    Example:
        >>> anchor = torch.randn(32, 128)
        >>> positive = torch.randn(32, 128)
        >>> negative = torch.randn(32, 128)
        >>> loss = triplet_loss(anchor, positive, negative, margin=1.0)
        >>> print(loss)
        tensor(0.1234)

    Notes:
        - Ensure that all input tensors have the same shape.
        - The function uses cosine similarity to compute distances.
        - The loss is averaged over the batch.
    """
    pos_dist = F.pairwise_distance(anchor, positive, p=2)
    neg_dist = F.pairwise_distance(anchor, negative, p=2)
    loss = torch.relu(pos_dist - neg_dist + margin)
    return loss.mean()