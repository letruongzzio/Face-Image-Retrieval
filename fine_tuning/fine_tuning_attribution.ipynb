{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from information_processing import load_partitions, load_attributes\n",
    "from celebA_class import CelebAAttributionDataset\n",
    "from model_training import train_model_attribution, plot_training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_DIRNAME = os.path.expanduser(\"~/image-processing-project/\")\n",
    "IMAGE_DIR = os.path.join(PARENT_DIRNAME, \"data/img_align_celeba/\")\n",
    "ATTR_DIR = os.path.join(PARENT_DIRNAME, \"data/list_attr_celeba.csv\")\n",
    "EVAL_PARTITION_DIR = os.path.join(PARENT_DIRNAME, \"data/list_eval_partition.csv\")\n",
    "MODEL_DIR = os.path.join(PARENT_DIRNAME, \"fine_tuning/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 202599 images with 40 attributes.\n"
     ]
    }
   ],
   "source": [
    "attributes, attr_names = load_attributes(ATTR_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 202599 images with partitions.\n"
     ]
    }
   ],
   "source": [
    "partitions = load_partitions(EVAL_PARTITION_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.75, scale=(0.01, 0.3), ratio=(1.0, 1.0), value=0, inplace =True)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we are not using the validation set for hypertunning, we can concatenate the training and validation sets\n",
    "train_dataset = CelebAAttributionDataset(IMAGE_DIR, attributes, partitions, partition_type=0, transform=train_transforms)\n",
    "val_dataset = CelebAAttributionDataset(IMAGE_DIR, attributes, partitions, partition_type=1, transform=train_transforms)\n",
    "test_dataset = CelebAAttributionDataset(IMAGE_DIR, attributes, partitions, partition_type=2, transform=test_transforms)\n",
    "# Concatenate the training and validation sets\n",
    "final_train_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "train_loader = DataLoader(final_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(final_train_dataset)}\\nTesting samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/letruongzzio/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/letruongzzio/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNet pre-trained model\n",
    "model = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the last 10\n",
    "for param in model.features[:-10].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Fine-tune classifier: \n",
    "num_features = model.last_channel\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, len(attr_names)),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multi-label classification\n",
    "# Only parameters that require gradients are optimized\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, history = train_model_attribution(model, train_loader, test_loader, criterion, optimizer, NUM_EPOCHS, device)\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), MODEL_DIR + \"/celeba_mobilenet_v2.pth\")\n",
    "print(f\"Model saved to {MODEL_DIR}/celeba_mobilenet_v2.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
